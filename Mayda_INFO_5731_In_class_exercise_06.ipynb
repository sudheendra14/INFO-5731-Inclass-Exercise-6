{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mayda INFO 5731 In_class_exercise_06.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/In_class_exercise/In_class_exercise_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7TahL04sVvR"
      },
      "source": [
        "# **The sixth in-class-exercise (20 points in total, 3/2/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyZITr8sjnh"
      },
      "source": [
        "## **1. Rule-based information extraction (10 points)**\n",
        "\n",
        "Use any keywords related to data science, natural language processing, machine learning to search from google scholar, get the **titles** of 100 articles (either by web scraping or manually) about this topic, define a set of patterns to extract the research questions/problems, methods/algorithms/models, datasets, applications, or any other important information about this topic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvR_O9D8sOUY",
        "outputId": "63b3df2a-cc99-42ef-f9c2-b2a98aa7e735"
      },
      "source": [
        "# Write your code here\r\n",
        "\r\n",
        "!pip uninstall tensorflow -y\r\n",
        "!pip install  tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.1:\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/dc/e8c5e7983866fa4ef3fd619faa35f660b95b01a2ab62b3884f038ccab542/tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3MB 39kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (54.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42mdUx9tIf2o",
        "outputId": "417891b7-8411-42b8-f63c-492e36231da1"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkNxiOaNI7aY"
      },
      "source": [
        "import pandas as pd\r\n",
        "import requests\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "name = []\r\n",
        "name_List = []\r\n",
        "\r\n",
        "page_number = [0,10,20,30,40,50]\r\n",
        "for i in page_number:\r\n",
        " page = requests.get('https://citeseerx.ist.psu.edu/search;jsessionid=87FF6C66EA09F22314C131669600CF98?q=natural+language+processing&t=doc&sort=rlv&start='+ str (i))\r\n",
        " soup = BeautifulSoup(page.content,'html.parser')\r\n",
        " name.append(soup.find_all('a',class_='remove doc_details'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNo-k34uJEZ1",
        "outputId": "177737af-1fb9-4204-b493-a684a3d48e4b"
      },
      "source": [
        "for j in name:\r\n",
        "  for k in range(len(j)):\r\n",
        "    name_List.append(j[k].get_text())\r\n",
        "\r\n",
        "name_List"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n                  Foundations of statistical natural language processing\\n',\n",
              " '\\n                  A Maximum Entropy approach to Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\n                  Linguistics and Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\nNatural language processing (almost) from scratch \\n                  ',\n",
              " '\\nNatural language processing\\n',\n",
              " '\\nNatural Language Processing/Robotics\\n                  ',\n",
              " '\\n                  Tutorial on Natural Language Processing\\n',\n",
              " '\\n                  Ambiguities in Natural Language Processing\\n',\n",
              " '\\n                  Statistical Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing for Information Retrieval\\n                  ',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\nNatural language processing of lyrics\\n                  ',\n",
              " '\\n                  Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging\\n                  ',\n",
              " '\\n                  Connectionist Natural Language Processing\\n',\n",
              " '\\n                  Chaos and Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing:\\n                  ',\n",
              " '\\nNatural language processing: an introduction\\n                  ',\n",
              " '\\n                  Overview of Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\n                  Evaluating Natural Language Processing Systems\\n                  ',\n",
              " '\\n                  Analysis and Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing using NLTK and\\n                  ',\n",
              " '\\nNatural Language Processing Complexity and Parallelism\\n                  ',\n",
              " '\\n                  Large Lexicons For Natural Language Processing:\\n                  ',\n",
              " '\\nNatural Language Processing: Structure and Complexity\\n                  ',\n",
              " '\\n                  Deep Learning for Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\nNatural Language Processing of Textual Requirements\\n                  ',\n",
              " '\\nNatural Language Processing and Information Retrieval\\n                  ',\n",
              " '\\nNatural language processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\n                  Ants for Natural Language Processing\\n',\n",
              " '\\n                  ontologies, natural language processing\\n',\n",
              " '\\nNatural language processing\\n',\n",
              " '\\n                  Retrieval or Natural Language Processing\\n',\n",
              " '\\n                  THESAURUSES FOR NATURAL LANGUAGE PROCESSING\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\nNatural Language Processing Section\\n                  ',\n",
              " '\\nNatural Language Processing for\\n                  ',\n",
              " '\\nNatural Language Processing Group\\n                  ',\n",
              " '\\n                  BIOMEDICAL NATURAL LANGUAGE PROCESSING\\n',\n",
              " '\\n                  learning in Natural Language Processing\\n',\n",
              " '\\n                  An Introduction to Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing 2\\n                  ',\n",
              " '\\n                  Integrating speech and natural-language processing\\n',\n",
              " '\\n                  Paradigm Merger in Natural Language Processing\\n',\n",
              " '\\n                  on Visual Tools for Natural Language Processing\\n',\n",
              " '\\n                  Description Logics for Natural Language Processing\\n',\n",
              " '\\n                  STRUCTURE LEARNING FOR NATURAL LANGUAGE PROCESSING\\n',\n",
              " '\\n                  Commercial applications of natural language processing\\n',\n",
              " '\\n                  2008. Networks and natural language processing\\n',\n",
              " '\\n                  Current Issues in Software Engineering for Natural Language Processing\\n',\n",
              " '\\n                  Kernelized Sorting for Natural Language Processing\\n',\n",
              " '\\n                  Distributional Approaches to Natural Language Processing\\n',\n",
              " '\\n                  Decomposable Modeling in Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing in Information Retrieval\\n                  ',\n",
              " '\\n                  Information Retrieval in Malayalam Using Natural Language Processing\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ogzmFZoJKfH",
        "outputId": "199560aa-c0f0-4bea-b9d1-a7b68a09895d"
      },
      "source": [
        "df = pd.DataFrame({'Title':name_List})\r\n",
        "outcome=df.values\r\n",
        "print(outcome)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['\\n                  Foundations of statistical natural language processing\\n']\n",
            " ['\\n                  A Maximum Entropy approach to Natural Language Processing\\n']\n",
            " ['\\nNatural Language Processing\\n']\n",
            " ['\\n                  Linguistics and Natural Language Processing\\n']\n",
            " ['\\nNatural Language Processing\\n']\n",
            " ['\\nNatural language processing (almost) from scratch \\n                  ']\n",
            " ['\\nNatural language processing\\n']\n",
            " ['\\nNatural Language Processing/Robotics\\n                  ']\n",
            " ['\\n                  Tutorial on Natural Language Processing\\n']\n",
            " ['\\n                  Ambiguities in Natural Language Processing\\n']\n",
            " ['\\n                  Statistical Natural Language Processing\\n']\n",
            " ['\\nNatural Language Processing for Information Retrieval\\n                  ']\n",
            " ['\\nNatural Language Processing\\n']\n",
            " ['\\nNatural language processing of lyrics\\n                  ']\n",
            " ['\\n                  Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging\\n                  ']\n",
            " ['\\n                  Connectionist Natural Language Processing\\n']\n",
            " ['\\n                  Chaos and Natural Language Processing\\n']\n",
            " ['\\nNatural Language Processing:\\n                  ']\n",
            " ['\\nNatural language processing: an introduction\\n                  ']\n",
            " ['\\n                  Overview of Natural Language Processing\\n']\n",
            " ['\\nNatural Language Processing\\n']\n",
            " ['\\n                  Evaluating Natural Language Processing Systems\\n                  ']\n",
            " ['\\n                  Analysis and Natural Language Processing\\n']\n",
            " ['\\nNatural Language Processing using NLTK and\\n                  ']\n",
            " ['\\nNatural Language Processing Complexity and Parallelism\\n                  ']\n",
            " ['\\n                  Large Lexicons For Natural Language Processing:\\n                  ']\n",
            " ['\\nNatural Language Processing: Structure and Complexity\\n                  ']\n",
            " ['\\n                  Deep Learning for Natural Language Processing\\n']\n",
            " ['\\nNatural Language Processing\\n']\n",
            " ['\\nNatural Language Processing of Textual Requirements\\n                  ']\n",
            " ['\\nNatural Language Processing and Information Retrieval\\n                  ']\n",
            " ['\\nNatural language processing\\n']\n",
            " ['\\nNatural Language Processing\\n']\n",
            " ['\\nNatural Language Processing\\n']\n",
            " ['\\n                  Ants for Natural Language Processing\\n']\n",
            " ['\\n                  ontologies, natural language processing\\n']\n",
            " ['\\nNatural language processing\\n']\n",
            " ['\\n                  Retrieval or Natural Language Processing\\n']\n",
            " ['\\n                  THESAURUSES FOR NATURAL LANGUAGE PROCESSING\\n']\n",
            " ['\\nNatural Language Processing\\n']\n",
            " ['\\nNatural Language Processing Section\\n                  ']\n",
            " ['\\nNatural Language Processing for\\n                  ']\n",
            " ['\\nNatural Language Processing Group\\n                  ']\n",
            " ['\\n                  BIOMEDICAL NATURAL LANGUAGE PROCESSING\\n']\n",
            " ['\\n                  learning in Natural Language Processing\\n']\n",
            " ['\\n                  An Introduction to Natural Language Processing\\n']\n",
            " ['\\nNatural Language Processing 2\\n                  ']\n",
            " ['\\n                  Integrating speech and natural-language processing\\n']\n",
            " ['\\n                  Paradigm Merger in Natural Language Processing\\n']\n",
            " ['\\n                  on Visual Tools for Natural Language Processing\\n']\n",
            " ['\\n                  Description Logics for Natural Language Processing\\n']\n",
            " ['\\n                  STRUCTURE LEARNING FOR NATURAL LANGUAGE PROCESSING\\n']\n",
            " ['\\n                  Commercial applications of natural language processing\\n']\n",
            " ['\\n                  2008. Networks and natural language processing\\n']\n",
            " ['\\n                  Current Issues in Software Engineering for Natural Language Processing\\n']\n",
            " ['\\n                  Kernelized Sorting for Natural Language Processing\\n']\n",
            " ['\\n                  Distributional Approaches to Natural Language Processing\\n']\n",
            " ['\\n                  Decomposable Modeling in Natural Language Processing\\n']\n",
            " ['\\nNatural Language Processing in Information Retrieval\\n                  ']\n",
            " ['\\n                  Information Retrieval in Malayalam Using Natural Language Processing\\n']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BDuf2YWJJb3k",
        "outputId": "b54bbc72-acfa-4833-c2c1-bae2360cce35"
      },
      "source": [
        "df.head(50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n                  Foundations of statistical...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n                  A Maximum Entropy approach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n                  Linguistics and Natural La...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\\nNatural language processing (almost) from sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\\nNatural language processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\\nNatural Language Processing/Robotics\\n      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>\\n                  Tutorial on Natural Langua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\\n                  Ambiguities in Natural Lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\\n                  Statistical Natural Langua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\\nNatural Language Processing for Information ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>\\nNatural language processing of lyrics\\n     ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>\\n                  Transformation-Based Error...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>\\n                  Connectionist Natural Lang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>\\n                  Chaos and Natural Language...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>\\nNatural Language Processing:\\n              ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>\\nNatural language processing: an introduction...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>\\n                  Overview of Natural Langua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>\\n                  Evaluating Natural Languag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>\\n                  Analysis and Natural Langu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>\\nNatural Language Processing using NLTK and\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>\\nNatural Language Processing Complexity and P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>\\n                  Large Lexicons For Natural...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>\\nNatural Language Processing: Structure and C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>\\n                  Deep Learning for Natural ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>\\nNatural Language Processing of Textual Requi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>\\nNatural Language Processing and Information ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>\\nNatural language processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>\\n                  Ants for Natural Language ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>\\n                  ontologies, natural langua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>\\nNatural language processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>\\n                  Retrieval or Natural Langu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>\\n                  THESAURUSES FOR NATURAL LA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>\\nNatural Language Processing Section\\n       ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>\\nNatural Language Processing for\\n           ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>\\nNatural Language Processing Group\\n         ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>\\n                  BIOMEDICAL NATURAL LANGUAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>\\n                  learning in Natural Langua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>\\n                  An Introduction to Natural...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>\\nNatural Language Processing 2\\n             ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>\\n                  Integrating speech and nat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>\\n                  Paradigm Merger in Natural...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>\\n                  on Visual Tools for Natura...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Title\n",
              "0   \\n                  Foundations of statistical...\n",
              "1   \\n                  A Maximum Entropy approach...\n",
              "2                     \\nNatural Language Processing\\n\n",
              "3   \\n                  Linguistics and Natural La...\n",
              "4                     \\nNatural Language Processing\\n\n",
              "5   \\nNatural language processing (almost) from sc...\n",
              "6                     \\nNatural language processing\\n\n",
              "7   \\nNatural Language Processing/Robotics\\n      ...\n",
              "8   \\n                  Tutorial on Natural Langua...\n",
              "9   \\n                  Ambiguities in Natural Lan...\n",
              "10  \\n                  Statistical Natural Langua...\n",
              "11  \\nNatural Language Processing for Information ...\n",
              "12                    \\nNatural Language Processing\\n\n",
              "13  \\nNatural language processing of lyrics\\n     ...\n",
              "14  \\n                  Transformation-Based Error...\n",
              "15  \\n                  Connectionist Natural Lang...\n",
              "16  \\n                  Chaos and Natural Language...\n",
              "17  \\nNatural Language Processing:\\n              ...\n",
              "18  \\nNatural language processing: an introduction...\n",
              "19  \\n                  Overview of Natural Langua...\n",
              "20                    \\nNatural Language Processing\\n\n",
              "21  \\n                  Evaluating Natural Languag...\n",
              "22  \\n                  Analysis and Natural Langu...\n",
              "23  \\nNatural Language Processing using NLTK and\\n...\n",
              "24  \\nNatural Language Processing Complexity and P...\n",
              "25  \\n                  Large Lexicons For Natural...\n",
              "26  \\nNatural Language Processing: Structure and C...\n",
              "27  \\n                  Deep Learning for Natural ...\n",
              "28                    \\nNatural Language Processing\\n\n",
              "29  \\nNatural Language Processing of Textual Requi...\n",
              "30  \\nNatural Language Processing and Information ...\n",
              "31                    \\nNatural language processing\\n\n",
              "32                    \\nNatural Language Processing\\n\n",
              "33                    \\nNatural Language Processing\\n\n",
              "34  \\n                  Ants for Natural Language ...\n",
              "35  \\n                  ontologies, natural langua...\n",
              "36                    \\nNatural language processing\\n\n",
              "37  \\n                  Retrieval or Natural Langu...\n",
              "38  \\n                  THESAURUSES FOR NATURAL LA...\n",
              "39                    \\nNatural Language Processing\\n\n",
              "40  \\nNatural Language Processing Section\\n       ...\n",
              "41  \\nNatural Language Processing for\\n           ...\n",
              "42  \\nNatural Language Processing Group\\n         ...\n",
              "43  \\n                  BIOMEDICAL NATURAL LANGUAG...\n",
              "44  \\n                  learning in Natural Langua...\n",
              "45  \\n                  An Introduction to Natural...\n",
              "46  \\nNatural Language Processing 2\\n             ...\n",
              "47  \\n                  Integrating speech and nat...\n",
              "48  \\n                  Paradigm Merger in Natural...\n",
              "49  \\n                  on Visual Tools for Natura..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "_mDPXzZTJi1m",
        "outputId": "8223a080-83a8-4894-b4ac-9e520326eeb1"
      },
      "source": [
        "str=\"\"\r\n",
        "for i in result:\r\n",
        "  str+=i[0]\r\n",
        "\r\n",
        "str"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n                  Foundations of statistical natural language processing\\n\\n                  A Maximum Entropy approach to Natural Language Processing\\n\\nNatural Language Processing\\n\\n                  Linguistics and Natural Language Processing\\n\\nNatural Language Processing\\n\\nNatural language processing (almost) from scratch \\n                  \\nNatural language processing\\n\\nNatural Language Processing/Robotics\\n                  \\n                  Tutorial on Natural Language Processing\\n\\n                  Ambiguities in Natural Language Processing\\n\\n                  Statistical Natural Language Processing\\n\\nNatural Language Processing for Information Retrieval\\n                  \\nNatural Language Processing\\n\\nNatural language processing of lyrics\\n                  \\n                  Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging\\n                  \\n                  Connectionist Natural Language Processing\\n\\n                  Chaos and Natural Language Processing\\n\\nNatural Language Processing:\\n                  \\nNatural language processing: an introduction\\n                  \\n                  Overview of Natural Language Processing\\n\\nNatural Language Processing\\n\\n                  Evaluating Natural Language Processing Systems\\n                  \\n                  Analysis and Natural Language Processing\\n\\nNatural Language Processing using NLTK and\\n                  \\nNatural Language Processing Complexity and Parallelism\\n                  \\n                  Large Lexicons For Natural Language Processing:\\n                  \\nNatural Language Processing: Structure and Complexity\\n                  \\n                  Deep Learning for Natural Language Processing\\n\\nNatural Language Processing\\n\\nNatural Language Processing of Textual Requirements\\n                  \\nNatural Language Processing and Information Retrieval\\n                  \\nNatural language processing\\n\\nNatural Language Processing\\n\\nNatural Language Processing\\n\\n                  Ants for Natural Language Processing\\n\\n                  ontologies, natural language processing\\n\\nNatural language processing\\n\\n                  Retrieval or Natural Language Processing\\n\\n                  THESAURUSES FOR NATURAL LANGUAGE PROCESSING\\n\\nNatural Language Processing\\n\\nNatural Language Processing Section\\n                  \\nNatural Language Processing for\\n                  \\nNatural Language Processing Group\\n                  \\n                  BIOMEDICAL NATURAL LANGUAGE PROCESSING\\n\\n                  learning in Natural Language Processing\\n\\n                  An Introduction to Natural Language Processing\\n\\nNatural Language Processing 2\\n                  \\n                  Integrating speech and natural-language processing\\n\\n                  Paradigm Merger in Natural Language Processing\\n\\n                  on Visual Tools for Natural Language Processing\\n\\n                  Description Logics for Natural Language Processing\\n\\n                  STRUCTURE LEARNING FOR NATURAL LANGUAGE PROCESSING\\n\\n                  Commercial applications of natural language processing\\n\\n                  2008. Networks and natural language processing\\n\\n                  Current Issues in Software Engineering for Natural Language Processing\\n\\n                  Kernelized Sorting for Natural Language Processing\\n\\n                  Distributional Approaches to Natural Language Processing\\n\\n                  Decomposable Modeling in Natural Language Processing\\n\\nNatural Language Processing in Information Retrieval\\n                  \\n                  Information Retrieval in Malayalam Using Natural Language Processing\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq2zB0KeJpPA",
        "outputId": "2a720d0c-5594-4ea3-8ce6-856caf3c3b9a"
      },
      "source": [
        "import string \r\n",
        "import nltk \r\n",
        "import spacy \r\n",
        "import pandas as pd \r\n",
        "import numpy as np \r\n",
        "import math \r\n",
        "from tqdm import tqdm \r\n",
        "\r\n",
        "from spacy.matcher import Matcher \r\n",
        "from spacy.tokens import Span \r\n",
        "from spacy import displacy \r\n",
        "\r\n",
        "pd.set_option('display.max_colwidth', 200)\r\n",
        "nlp = spacy.load(\"en_core_web_sm\")\r\n",
        "doc = nlp(str)\r\n",
        "\r\n",
        "# print dependency tags and POS \r\n",
        "for tok in doc: \r\n",
        "  print(tok.text, \"-->\",tok.dep_, \"-->\",tok.pos_)\r\n",
        "\r\n",
        "# Matche the class object \r\n",
        "matcher = Matcher(nlp.vocab) \r\n",
        "\r\n",
        "#define  patterns \r\n",
        "pattern = [{'DEP':'amod', 'OP':\"?\"}, \r\n",
        "           {'POS':'NOUN'}, \r\n",
        "           {'LOWER': 'and', 'OP':\"?\"}, \r\n",
        "           {'LOWER': 'or', 'OP':\"?\"}, \r\n",
        "           {'LOWER': 'other'}, \r\n",
        "           {'POS': 'NOUN'}] \r\n",
        "           \r\n",
        "matcher.add(\"matching_1\", None, pattern) \r\n",
        "\r\n",
        "matches = matcher(doc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                   -->  --> SPACE\n",
            "Foundations --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "statistical --> amod --> ADJ\n",
            "natural --> amod --> ADJ\n",
            "language --> pobj --> NOUN\n",
            "processing --> acl --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "A --> det --> DET\n",
            "Maximum --> compound --> ADJ\n",
            "Entropy --> compound --> ADJ\n",
            "approach --> dobj --> NOUN\n",
            "to --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Linguistics --> pobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> ROOT --> NOUN\n",
            "( --> punct --> PUNCT\n",
            "almost --> advmod --> ADV\n",
            ") --> punct --> PUNCT\n",
            "from --> prep --> ADP\n",
            "scratch --> nmod --> NOUN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> nmod --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "/ --> punct --> SYM\n",
            "Robotics --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Tutorial --> ROOT --> PROPN\n",
            "on --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Ambiguities --> pobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> pobj --> PROPN\n",
            "Processing --> ROOT --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Statistical --> compound --> PROPN\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> dobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "Information --> compound --> PROPN\n",
            "Retrieval --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "lyrics --> pobj --> NOUN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Transformation --> npadvmod --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Based --> amod --> PROPN\n",
            "Error --> npadvmod --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Driven --> nmod --> VERB\n",
            "Learning --> nmod --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> ROOT --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "A --> det --> DET\n",
            "Case --> compound --> PROPN\n",
            "Study --> ROOT --> PROPN\n",
            "in --> prep --> ADP\n",
            "Part --> nmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "of --> prep --> ADP\n",
            "- --> punct --> PUNCT\n",
            "Speech --> pobj --> NOUN\n",
            "Tagging --> pobj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Connectionist --> compound --> PROPN\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Chaos --> conj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> conj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> appos --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "an --> det --> DET\n",
            "introduction --> appos --> NOUN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Overview --> conj --> NOUN\n",
            "of --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> pobj --> PROPN\n",
            "Processing --> ROOT --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> ROOT --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Evaluating --> nmod --> VERB\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Systems --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Analysis --> dobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> ROOT --> NOUN\n",
            "using --> acl --> VERB\n",
            "NLTK --> dobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Complexity --> conj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Parallelism --> conj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Large --> amod --> ADJ\n",
            "Lexicons --> dobj --> NOUN\n",
            "For --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> appos --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "Structure --> appos --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Complexity --> conj --> NOUN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Deep --> compound --> ADJ\n",
            "Learning --> conj --> NOUN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "Textual --> compound --> PROPN\n",
            "Requirements --> pobj --> NOUN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> nmod --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Information --> conj --> PROPN\n",
            "Retrieval --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> acl --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Ants --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "ontologies --> pobj --> NOUN\n",
            ", --> punct --> PUNCT\n",
            "natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> conj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> nmod --> NOUN\n",
            "processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Retrieval --> conj --> PROPN\n",
            "or --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> amod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "THESAURUSES --> ROOT --> NOUN\n",
            "FOR --> prep --> ADP\n",
            "NATURAL --> amod --> ADJ\n",
            "LANGUAGE --> compound --> NOUN\n",
            "PROCESSING --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Section --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> ROOT --> PROPN\n",
            "for --> prep --> ADP\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Group --> pobj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "BIOMEDICAL --> compound --> PROPN\n",
            "NATURAL --> amod --> PROPN\n",
            "LANGUAGE --> nsubj --> PROPN\n",
            "PROCESSING --> nmod --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "learning --> ROOT --> VERB\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "An --> det --> DET\n",
            "Introduction --> ROOT --> NOUN\n",
            "to --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> pobj --> PROPN\n",
            "Processing --> acl --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> ROOT --> PROPN\n",
            "2 --> nummod --> NUM\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Integrating --> compound --> VERB\n",
            "speech --> dobj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "natural --> amod --> ADJ\n",
            "- --> punct --> PUNCT\n",
            "language --> conj --> NOUN\n",
            "processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Paradigm --> compound --> PROPN\n",
            "Merger --> conj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "on --> prep --> ADP\n",
            "Visual --> compound --> ADJ\n",
            "Tools --> pobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Description --> compound --> PROPN\n",
            "Logics --> pobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "STRUCTURE --> compound --> PROPN\n",
            "LEARNING --> pobj --> NOUN\n",
            "FOR --> prep --> ADP\n",
            "NATURAL --> amod --> PROPN\n",
            "LANGUAGE --> compound --> NOUN\n",
            "PROCESSING --> nmod --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Commercial --> amod --> ADJ\n",
            "applications --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> pcomp --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "2008 --> npadvmod --> NUM\n",
            ". --> punct --> PUNCT\n",
            "Networks --> nsubj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "natural --> amod --> ADJ\n",
            "language --> conj --> NOUN\n",
            "processing --> acl --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Current --> compound --> PROPN\n",
            "Issues --> dobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Software --> compound --> PROPN\n",
            "Engineering --> pobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Kernelized --> compound --> VERB\n",
            "Sorting --> pobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Distributional --> compound --> ADJ\n",
            "Approaches --> pobj --> NOUN\n",
            "to --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Decomposable --> compound --> ADJ\n",
            "Modeling --> pobj --> NOUN\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Information --> compound --> PROPN\n",
            "Retrieval --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Information --> compound --> PROPN\n",
            "Retrieval --> pobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Malayalam --> pobj --> PROPN\n",
            "Using --> ROOT --> VERB\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> dobj --> NOUN\n",
            "\n",
            " -->  --> SPACE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CcwKTzlJ9m6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq_7VGmrsum4"
      },
      "source": [
        "## **2. Domain-specific information extraction (10 points)**\n",
        "\n",
        "For the legal case used in the data cleaning exercise: [01-05-1 Adams v Tanner.txt](https://raw.githubusercontent.com/unt-iialab/info5731_spring2021/main/class_exercises/01-05-1%20%20Adams%20v%20Tanner.txt), use [legalNLP](https://lexpredict-lexnlp.readthedocs.io/en/latest/modules/extract/extract.html#nlp-based-extraction-methods) to extract the following inforation from the text (if the information is not exist, just print None):\n",
        "\n",
        "(1) acts, e.g., “section 1 of the Advancing Hope Act, 1986”\n",
        "\n",
        "(2) amounts, e.g., “ten pounds” or “5.8 megawatts”\n",
        "\n",
        "(3) citations, e.g., “10 U.S. 100” or “1998 S. Ct. 1”\n",
        "\n",
        "(4) companies, e.g., “Lexpredict LLC”\n",
        "\n",
        "(5) conditions, e.g., “subject to …” or “unless and until …”\n",
        "\n",
        "(6) constraints, e.g., “no more than”\n",
        "\n",
        "(7) copyright, e.g., “(C) Copyright 2000 Acme”\n",
        "\n",
        "(8) courts, e.g., “Supreme Court of New York”\n",
        "\n",
        "(9) CUSIP, e.g., “392690QT3”\n",
        "\n",
        "(10) dates, e.g., “June 1, 2017” or “2018-01-01”\n",
        "\n",
        "(11) definitions, e.g., “Term shall mean …”\n",
        "\n",
        "(12) distances, e.g., “fifteen miles”\n",
        "\n",
        "(13) durations, e.g., “ten years” or “thirty days”\n",
        "\n",
        "(14) geographic and geopolitical entities, e.g., “New York” or “Norway”\n",
        "\n",
        "(15) money and currency usages, e.g., “$5” or “10 Euro”\n",
        "\n",
        "(16) percents and rates, e.g., “10%” or “50 bps”\n",
        "\n",
        "(17) PII, e.g., “212-212-2121” or “999-999-9999”\n",
        "\n",
        "(18) ratios, e.g.,” 3:1” or “four to three”\n",
        "\n",
        "(19) regulations, e.g., “32 CFR 170”\n",
        "\n",
        "(20) trademarks, e.g., “MyApp (TM)”\n",
        "\n",
        "(21) URLs, e.g., “http://acme.com/”\n",
        "\n",
        "(22) addresses, e.g., “1999 Mount Read Blvd, Rochester, NY, USA, 14615”\n",
        "\n",
        "(23) persons, e.g., “John Doe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc7NtJrLx5tS",
        "outputId": "03f68c60-6d2a-447d-c393-34c615990b9e"
      },
      "source": [
        "# write your code here\r\n",
        "!pip install pysbd\r\n",
        "!pip install lexnlp==0.2.7\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "nltk.download('wordnet')\r\n",
        "import lexnlp.extract.en\r\n",
        "import lexnlp.extract.en.citations\r\n",
        "import lexnlp.extract.en.entities.nltk_re\r\n",
        "import lexnlp.extract.en.conditions\r\n",
        "import lexnlp.extract.en.constraints\r\n",
        "import lexnlp.extract.en.copyright\r\n",
        "import lexnlp.extract.en.courts\r\n",
        "import lexnlp.extract.en.cusip\r\n",
        "import lexnlp.extract.en.dates\r\n",
        "import lexnlp.extract.en.definitions\r\n",
        "import lexnlp.extract.en.distances\r\n",
        "import lexnlp.extract.en.durations\r\n",
        "import lexnlp.extract.en.geoentities\r\n",
        "import lexnlp.extract.en.money\r\n",
        "import lexnlp.extract.en.percents\r\n",
        "import lexnlp.extract.en.pii\r\n",
        "import lexnlp.extract.en.ratios\r\n",
        "import lexnlp.extract.en.regulations\r\n",
        "import lexnlp.extract.en.trademarks\r\n",
        "import lexnlp.extract.en.urls\r\n",
        "\r\n",
        "text= (open(\"01-05-1  Adams v Tanner.txt\", \"r\")).read()\r\n",
        "print(\"acts:  \",list(lexnlp.extract.en.acts.get_acts(text)))\r\n",
        "print(\"amounts: \",list(lexnlp.extract.en.amounts.get_amounts(text)))\r\n",
        "print(\"citations: \", list(lexnlp.extract.en.citations.get_citations(text)))\r\n",
        "print(\"companies: \",list(lexnlp.extract.en.entities.nltk_re.get_companies(text)))\r\n",
        "print(\"conditions:\",list(lexnlp.extract.en.conditions.get_conditions(text)))\r\n",
        "print(\"constraints:\",list(lexnlp.extract.en.constraints.get_constraints(text)))\r\n",
        "print(\"copyright:\",list(lexnlp.extract.en.copyright.get_copyright(text)))\r\n",
        "print(\"dates:\",list(lexnlp.extract.en.dates.get_dates(text)))\r\n",
        "print(\"distances\",list(lexnlp.extract.en.distances.get_distances(text)))\r\n",
        "print(\"durations:\",list(lexnlp.extract.en.durations.get_durations(text)))\r\n",
        "print(\"cusip:\",list(lexnlp.extract.en.cusip.get_cusip(text)))\r\n",
        "print(\"definations\",list(lexnlp.extract.en.definitions.get_definitions(text)))\r\n",
        "print(\"money\",list(lexnlp.extract.en.money.get_money(text)))\r\n",
        "print(\"percents\",list(lexnlp.extract.en.percents.get_percents(text)))\r\n",
        "print(\"pii\",list(lexnlp.extract.en.pii.get_pii(text)))\r\n",
        "print(\"ratios\",list(lexnlp.extract.en.ratios.get_ratios(text)))\r\n",
        "print(\"regualtons\",list(lexnlp.extract.en.regulations.get_regulations(text)))\r\n",
        "print(\"trademarks:\",list(lexnlp.extract.en.trademarks.get_trademarks(text)))\r\n",
        "print(\"urls\",list(lexnlp.extract.en.urls.get_urls(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pysbd in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Collecting lexnlp==0.2.7\n",
            "  Using cached https://files.pythonhosted.org/packages/50/50/e5e769dfa27b9c657bc3fefb6edee56d186c630176746e232030aa5409ed/lexnlp-0.2.7-py3-none-any.whl\n",
            "Collecting pandas==0.23.4\n",
            "  Using cached https://files.pythonhosted.org/packages/67/a7/12261a51ac2e7be4c698ca27cbe364ca5f16d64999456ee47ea8c7b44417/pandas-0.23.4-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: reporters-db==1.0.12.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp==0.2.7) (1.0.12.1)\n",
            "Processing /root/.cache/pip/wheels/36/f1/5c/f667347d86a3a534ba4c0127eed4389f929916e3ec88bb461a/nltk-3.2.4-cp37-none-any.whl\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.7/dist-packages (from lexnlp==0.2.7) (2.22.0)\n",
            "Processing /root/.cache/pip/wheels/2a/5f/2d/04fe5cffea90fbba14c8eab40f519096c8558cceaaa6777048/gensim-3.4.0-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: us==1.0.0 in /usr/local/lib/python3.7/dist-packages (from lexnlp==0.2.7) (1.0.0)\n",
            "Collecting scipy==1.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/d0/73/76fc6ea21818eed0de8dd38e1e9586725578864169a2b31acdeffb9131c8/scipy-1.0.0.tar.gz\n",
            "Requirement already satisfied: dateparser==0.7.0 in /usr/local/lib/python3.7/dist-packages (from lexnlp==0.2.7) (0.7.0)\n",
            "Collecting datefinder-lexpredict==0.6.2\n",
            "  Using cached https://files.pythonhosted.org/packages/27/47/9a38724045b30e2e4d1c5e3e08fd3b0770dedb2e9ca92c1347b9e2182470/datefinder_lexpredict-0.6.2-py2.py3-none-any.whl\n",
            "Collecting pycountry==18.5.26\n",
            "  Using cached https://files.pythonhosted.org/packages/c5/c0/8ce9d2b55347867900edbe4d18f790571130c16f882b4891a0f08627dcdc/pycountry-18.5.26-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Unidecode==0.4.21 in /usr/local/lib/python3.7/dist-packages (from lexnlp==0.2.7) (0.4.21)\n",
            "Collecting num2words==0.5.5\n",
            "  Using cached https://files.pythonhosted.org/packages/5f/d8/1c1fb47cce56ff2cc1f5eb2740f2679045769778a746fbf9ebff1d70a63e/num2words-0.5.5-py2.py3-none-any.whl\n",
            "Collecting typing==3.6.2\n",
            "  Using cached https://files.pythonhosted.org/packages/44/88/d09c6a7fe1af4a02f16d2f1766212bec752aadb04e5699a9706a10a1a37d/typing-3.6.2-py3-none-any.whl\n",
            "Collecting scikit-learn==0.19.1\n",
            "  Using cached https://files.pythonhosted.org/packages/f5/2c/5edf2488897cad4fb8c4ace86369833552615bf264460ae4ef6e1f258982/scikit-learn-0.19.1.tar.gz\n",
            "Requirement already satisfied: regex==2017.9.23 in /usr/local/lib/python3.7/dist-packages (from lexnlp==0.2.7) (2017.9.23)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4->lexnlp==0.2.7) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4->lexnlp==0.2.7) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4->lexnlp==0.2.7) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from reporters-db==1.0.12.1->lexnlp==0.2.7) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->lexnlp==0.2.7) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->lexnlp==0.2.7) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->lexnlp==0.2.7) (2020.12.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->lexnlp==0.2.7) (3.0.4)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0->lexnlp==0.2.7) (4.2.0)\n",
            "Requirement already satisfied: jellyfish==0.5.6 in /usr/local/lib/python3.7/dist-packages (from us==1.0.0->lexnlp==0.2.7) (0.5.6)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.0->lexnlp==0.2.7) (1.5.1)\n",
            "Building wheels for collected packages: scipy, scikit-learn\n",
            "  Building wheel for scipy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scipy\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for scipy\n",
            "\u001b[31m  ERROR: Failed cleaning build dir for scipy\u001b[0m\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for scikit-learn\n",
            "Failed to build scipy scikit-learn\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement scikit-learn>=0.22, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas, nltk, scipy, gensim, datefinder-lexpredict, pycountry, num2words, typing, scikit-learn, lexnlp\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}